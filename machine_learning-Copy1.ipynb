{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\\\n",
    "                             GradientBoostingClassifier, ExtraTreesClassifier,\\\n",
    "                             BaggingClassifier, VotingClassifier)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set de entrenamiento y Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los archivos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_final.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos las variables categ√≥ricas al tipo correspondiente, para reducir el uso de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['rango_edad'] = train['rango_edad'].astype('category')\n",
    "#train['sexo'] = train['sexo'].astype('category') \n",
    "#train['nivel_estudios'] = train['nivel_estudios'].astype('category')\n",
    "#train['esta_estudiando'] = train['esta_estudiando'].astype('category')\n",
    "#train['tipo_de_trabajo'] = train['tipo_de_trabajo'].astype('category')\n",
    "#train['nivel_laboral'] = train['nivel_laboral'].astype('category')\n",
    "#train['nombre_zona'] = train['nombre_zona'].astype('category')\n",
    "#train['num_area'] = train['num_area'].astype('category')\n",
    "#train['post_por_nivel'] = train['post_por_nivel'].astype('category')\n",
    "#train['sepostulo'] = train['sepostulo'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_final['rango_edad'] = test_final['rango_edad'].astype('category')\n",
    "#test_final['sexo'] = test_final['sexo'].astype('category') \n",
    "#test_final['nivel_estudios'] = test_final['nivel_estudios'].astype('category')\n",
    "#test_final['esta_estudiando'] = test_final['esta_estudiando'].astype('category')\n",
    "#test_final['tipo_de_trabajo'] = test_final['tipo_de_trabajo'].astype('category')\n",
    "#test_final['nivel_laboral'] = test_final['nivel_laboral'].astype('category')\n",
    "#test_final['nombre_zona'] = test_final['nombre_zona'].astype('category')\n",
    "#test_final['num_area'] = test_final['num_area'].astype('category')\n",
    "#test_final['post_por_nivel'] = test_final['post_por_nivel'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos guardamos los IDs necesarios para el submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id_aviso_postulante = test_final['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos el set de entrenamiento y el test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>brand listing</th>\n",
       "      <th>checkout</th>\n",
       "      <th>conversion</th>\n",
       "      <th>generic listing</th>\n",
       "      <th>searched products</th>\n",
       "      <th>staticpage</th>\n",
       "      <th>viewed product</th>\n",
       "      <th>visited site</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>64a3c2f6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>b866afff</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>947126c0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2b81e8f3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>f4924234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        person  brand listing  checkout  conversion  generic listing  \\\n",
       "380   64a3c2f6           14.0       0.0         0.0              1.0   \n",
       "705   b866afff           39.0       4.0         2.0             28.0   \n",
       "1474  947126c0            0.0       1.0         0.0              2.0   \n",
       "160   2b81e8f3           10.0       1.0         1.0             19.0   \n",
       "1321  f4924234            1.0       2.0         0.0              0.0   \n",
       "\n",
       "      searched products  staticpage  viewed product  visited site  label  \n",
       "380                 0.0         0.0            13.0           7.0    1.0  \n",
       "705               101.0         2.0            78.0          20.0    1.0  \n",
       "1474                0.0         0.0             2.0           1.0    0.0  \n",
       "160                 0.0         0.0           115.0           9.0    1.0  \n",
       "1321                0.0         0.0            20.0           5.0    0.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1980 entries, 0 to 1979\n",
      "Data columns (total 10 columns):\n",
      "person               1980 non-null object\n",
      "brand listing        1980 non-null float64\n",
      "checkout             1980 non-null float64\n",
      "conversion           1980 non-null float64\n",
      "generic listing      1980 non-null float64\n",
      "searched products    1980 non-null float64\n",
      "staticpage           1980 non-null float64\n",
      "viewed product       1980 non-null float64\n",
      "visited site         1980 non-null float64\n",
      "label                1980 non-null float64\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 154.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-501e9d78f4e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_final' is not defined"
     ]
    }
   ],
   "source": [
    "test_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19414 entries, 0 to 19413\n",
      "Data columns (total 10 columns):\n",
      "person               19414 non-null object\n",
      "label                19414 non-null int64\n",
      "brand listing        19414 non-null float64\n",
      "checkout             19414 non-null float64\n",
      "conversion           19414 non-null float64\n",
      "generic listing      19414 non-null float64\n",
      "searched products    19414 non-null float64\n",
      "staticpage           19414 non-null float64\n",
      "viewed product       19414 non-null float64\n",
      "visited site         19414 non-null float64\n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos guardamos los features que utilizaremos para los algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'brand listing', 'checkout', 'conversion', 'generic listing',\n",
       "       'searched products', 'staticpage', 'viewed product', 'visited site',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "f1 = 'ad campaign hit'\n",
    "f2 = 'brand listing'\n",
    "f3 = 'checkout'\n",
    "f4 = 'conversion'\n",
    "f5 = 'generic listing'\n",
    "f6 = 'search engine hit'\n",
    "f7 = 'viewed product'\n",
    "f8 = 'visited site'\n",
    "f9 = 'searched products'\n",
    "f10= 'staticpage'\n",
    "\n",
    "features = [f2,f3,f4,f5,f9,f10,f7,f8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionamos el set de entrenamiento para realizar pruebas locales de hiper-par√°metros antes de realizar cada submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = 0.25\n",
    "random_s = 0\n",
    "\n",
    "x = np.array(train[features])\n",
    "y = np.array(train['label'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_s, random_state=random_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el set de entrenamiento para el test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_final = np.array(test_final[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos probados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores iniciales para K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALORES INICIALES PARA K\n",
      "La precisi√≥n para k= 5 es: 0.6240892606266539\n",
      "La precisi√≥n para k= 10 es: 0.5904695004410755\n",
      "La precisi√≥n para k= 20 es: 0.6194089587349298\n",
      "La precisi√≥n para k= 50 es: 0.609460254190218\n",
      "La precisi√≥n para k= 60 es: 0.6054170614565296\n",
      "La precisi√≥n para k= 75 es: 0.6176528245172672\n",
      "La precisi√≥n para k= 80 es: 0.6150472114222236\n",
      "Con k= 5 se obtuvo la mayor precisi√≥n: 0.6240892606266539\n",
      "Tiempo de ejecuci√≥n: 0.07623 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "print('VALORES INICIALES PARA K')\n",
    "\n",
    "k_valores = [5,10,20,50,60,75,80]\n",
    "mejor_k = 0\n",
    "mejor_precision = 0\n",
    "\n",
    "for k in k_valores:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred = knn.predict(x_test)\n",
    "    precision = roc_auc_score(y_test, pred)\n",
    "    print('La precisi√≥n para k=', k, 'es:',precision)\n",
    "    if precision > mejor_precision:\n",
    "        mejor_precision = precision\n",
    "        mejor_k = k\n",
    "        \n",
    "print('Con k=', mejor_k, 'se obtuvo la mayor precisi√≥n:', mejor_precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores grid search para K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALORES GRID SEARCH PARA K\n",
      "La precisi√≥n para k = 3 es: 0.6104159179272716\n",
      "La precisi√≥n para k = 4 es: 0.5819093671382364\n",
      "La precisi√≥n para k = 5 es: 0.6240892606266539\n",
      "La precisi√≥n para k = 6 es: 0.6133482536674617\n",
      "La precisi√≥n para k = 7 es: 0.6245140000653445\n",
      "Con k= 7 se obtuvo la mayor precisi√≥n: 0.6245140000653445\n",
      "Tiempo de ejecuci√≥n: 0.03891 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "print('VALORES GRID SEARCH PARA K')\n",
    "\n",
    "k_valores = []\n",
    "\n",
    "for i in range(mejor_k-2, mejor_k+3):\n",
    "    k_valores.append(i)\n",
    "    \n",
    "for k in k_valores:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred = knn.predict(x_test)\n",
    "    precision = roc_auc_score(y_test, pred)\n",
    "    print('La precisi√≥n para k =', k, 'es:',precision)\n",
    "    if precision > mejor_precision:\n",
    "        mejor_precision = precision\n",
    "        mejor_k = k\n",
    "        \n",
    "print('Con k=', mejor_k, 'se obtuvo la mayor precisi√≥n:', mejor_precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecimos el test final con el mejor k obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=mejor_k)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "knn.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = knn.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5030102428299084"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "#submit.to_csv('submits/submit_knn.csv', index=False)\n",
    "\n",
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n:  0.5321377840909091\n",
      "Tiempo de ejecuci√≥n: 0.07748 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Par√°metros √≥ptimos\n",
    "params_optimos_rf = {'n_estimators':50, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "# Creamos el Random Forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "random_forest.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = random_forest.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f0f0aaf860a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Predecimos las postulaciones del set final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpred_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test_final' is not defined"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el random forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "random_forest.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = random_forest.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.19884 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el random forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "random_forest.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = random_forest.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5471577032679189"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_random_forest_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46414566694639225"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extra Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n:  0.6439948377822067\n",
      "Tiempo de ejecuci√≥n: 0.14023 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Par√°metros √≥ptimos\n",
    "params_optimos_et = {'n_estimators':100, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "# Creamos el extra_trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "extra_trees.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = extra_trees.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.36203 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el extra trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "extra_trees.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = extra_trees.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.37548 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el extra trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "extra_trees.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = extra_trees.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_extra_trees.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47906535837726644"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4952222268966175"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_extra_trees_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n:  0.5437236579867352\n",
      "Tiempo de ejecuci√≥n: 0.00285 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "naive_bayes.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = naive_bayes.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.00517 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "naive_bayes.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = naive_bayes.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.10010 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "naive_bayes.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = naive_bayes.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_naive_bayes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3924665602380694"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49787637307282695"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_naive_bayes_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n:  0.5467050021236971\n",
      "Tiempo de ejecuci√≥n: 0.00344 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el perceptron\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "perceptron.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = perceptron.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.05273 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el perceptron\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "perceptron.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = perceptron.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_perceptron.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5572845651225663"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Adaptive Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n:  0.7524095795079558\n",
      "Tiempo de ejecuci√≥n: 0.10293 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Par√°metros √≥ptimos\n",
    "params_optimos_ab = {'n_estimators':50}\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "ada_boost.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = ada_boost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.00789 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "ada_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = ada_boost.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.00770 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "ada_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = ada_boost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_ada_boost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5471577032679189"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5471577032679189"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_ada_boost_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n:  0.7330430947168949\n",
      "Tiempo de ejecuci√≥n: 0.18140 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Par√°metros √≥ptimos\n",
    "params_optimos_gb = {'learning_rate':0.1, 'n_estimators':150, 'max_depth':4, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'subsample':0.5, 'max_features':'sqrt', 'warm_start':True}\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "gra_boost.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = gra_boost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.45478 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "gra_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = gra_boost.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.44393 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "gra_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = gra_boost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5471577032679189"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_gra_boost.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4538110866566438"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_gra_boost_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n:  0.9982788296041308\n",
      "Tiempo de ejecuci√≥n: 0.05618 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "log_reg.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = log_reg.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.01917 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "log_reg.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = log_reg.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.02007 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "log_reg.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = log_reg.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5218849707616582"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_log_reg.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.457112218327713"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_log_reg_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n:  0.9991394148020654\n",
      "Tiempo de ejecuci√≥n: 0.00425 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Par√°metros √≥ptimos\n",
    "params_optimos_dt = {'criterion':'entropy', 'splitter':'best', 'max_depth':None, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'max_features':'sqrt', 'presort':True}\n",
    "\n",
    "# Creamos el logistic regression\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "decision_tree.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = decision_tree.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.00415 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el decision tree\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "decision_tree.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = decision_tree.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.00482 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el decision tree\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "decision_tree.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = decision_tree.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5471577032679189"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_decision_tree.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5471577032679189"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_decision_tree_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Con Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n:  0.9987091222030982\n",
      "Tiempo de ejecuci√≥n: 1.31514 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Par√°metros √≥ptimos\n",
    "params_optimos_bag_lr = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "bagging.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = bagging.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 1.73081 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "params_optimos_bag_lr = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = bagging.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 1.71528 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "params_optimos_bag_lr = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = bagging.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5219441449141228"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_bagging_log_reg.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47188856881583063"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_bagging_log_reg_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Con Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n:  0.9569707401032702\n",
      "Tiempo de ejecuci√≥n: 0.09848 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Par√°metros √≥ptimos\n",
    "params_optimos_bag_dt = {'base_estimator':DecisionTreeClassifier(**params_optimos_dt), 'n_estimators':10, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "bagging.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = bagging.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.08380 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = bagging.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.09353 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = bagging.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5471577032679189"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_bagging_decision_tree.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4848502545208166"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_bagging_decision_tree_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n:  1.0\n",
      "Tiempo de ejecuci√≥n: 10.26045 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariano/ENTER/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Creamos los estimadores base que utilizaremos para el voting\n",
    "estimador_1 = DecisionTreeClassifier(**params_optimos_dt)\n",
    "estimador_2 = GradientBoostingClassifier(**params_optimos_gb)\n",
    "estimador_3 = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Los agregamos a la lista de estimadores\n",
    "estimadores = []\n",
    "estimadores.append(('Naive Bayes', estimador_1))\n",
    "estimadores.append(('Logistic Regression', estimador_2))\n",
    "estimadores.append(('Random Forest', estimador_3))\n",
    "\n",
    "# Creamos el voting\n",
    "voting = VotingClassifier(estimators=estimadores)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "voting.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = voting.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.91246 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariano/ENTER/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el voting\n",
    "voting = VotingClassifier(estimators=estimadores)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "voting.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = voting.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5471577032679189"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_voting.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-64-768a22ffce3e>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-768a22ffce3e>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    xgboost = xgb.XGBClassifier(learning_rate = 0.02,                            n_estimators= 2000,                            max_depth= 5,                            min_child_weight= 2,                            gamma=0.9,\\\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\                        \n",
    "                            subsample=0.7,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "xgboost.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred_final = xgboost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisi√≥n\n",
    "precision = accuracy_score(y_test, pred_final)\n",
    "\n",
    "print(\"Precisi√≥n: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 1.03294 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariano/ENTER/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "xgboost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = xgboost.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n: 0.71449 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "xgboost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = xgboost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecuci√≥n: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5471577032679189"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_xgboost.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41126946547307214"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_xgboost_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
