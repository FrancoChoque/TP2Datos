{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariano/ENTER/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/home/mariano/ENTER/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\\\n",
    "                             GradientBoostingClassifier, ExtraTreesClassifier,\\\n",
    "                             BaggingClassifier, VotingClassifier)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set de entrenamiento y Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los archivos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_final.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos las variables categóricas al tipo correspondiente, para reducir el uso de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['rango_edad'] = train['rango_edad'].astype('category')\n",
    "#train['sexo'] = train['sexo'].astype('category') \n",
    "#train['nivel_estudios'] = train['nivel_estudios'].astype('category')\n",
    "#train['esta_estudiando'] = train['esta_estudiando'].astype('category')\n",
    "#train['tipo_de_trabajo'] = train['tipo_de_trabajo'].astype('category')\n",
    "#train['nivel_laboral'] = train['nivel_laboral'].astype('category')\n",
    "#train['nombre_zona'] = train['nombre_zona'].astype('category')\n",
    "#train['num_area'] = train['num_area'].astype('category')\n",
    "#train['post_por_nivel'] = train['post_por_nivel'].astype('category')\n",
    "#train['sepostulo'] = train['sepostulo'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_final['rango_edad'] = test_final['rango_edad'].astype('category')\n",
    "#test_final['sexo'] = test_final['sexo'].astype('category') \n",
    "#test_final['nivel_estudios'] = test_final['nivel_estudios'].astype('category')\n",
    "#test_final['esta_estudiando'] = test_final['esta_estudiando'].astype('category')\n",
    "#test_final['tipo_de_trabajo'] = test_final['tipo_de_trabajo'].astype('category')\n",
    "#test_final['nivel_laboral'] = test_final['nivel_laboral'].astype('category')\n",
    "#test_final['nombre_zona'] = test_final['nombre_zona'].astype('category')\n",
    "#test_final['num_area'] = test_final['num_area'].astype('category')\n",
    "#test_final['post_por_nivel'] = test_final['post_por_nivel'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos guardamos los IDs necesarios para el submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id_aviso_postulante = test_final['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos el set de entrenamiento y el test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>brand listing</th>\n",
       "      <th>checkout</th>\n",
       "      <th>conversion</th>\n",
       "      <th>generic listing</th>\n",
       "      <th>searched products</th>\n",
       "      <th>staticpage</th>\n",
       "      <th>viewed product</th>\n",
       "      <th>visited site</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>64a3c2f6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>b866afff</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>947126c0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2b81e8f3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>f4924234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        person  brand listing  checkout  conversion  generic listing  \\\n",
       "380   64a3c2f6           14.0       0.0         0.0              1.0   \n",
       "705   b866afff           39.0       4.0         2.0             28.0   \n",
       "1474  947126c0            0.0       1.0         0.0              2.0   \n",
       "160   2b81e8f3           10.0       1.0         1.0             19.0   \n",
       "1321  f4924234            1.0       2.0         0.0              0.0   \n",
       "\n",
       "      searched products  staticpage  viewed product  visited site  label  \n",
       "380                 0.0         0.0            13.0           7.0    1.0  \n",
       "705               101.0         2.0            78.0          20.0    1.0  \n",
       "1474                0.0         0.0             2.0           1.0    0.0  \n",
       "160                 0.0         0.0           115.0           9.0    1.0  \n",
       "1321                0.0         0.0            20.0           5.0    0.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1980 entries, 0 to 1979\n",
      "Data columns (total 10 columns):\n",
      "person               1980 non-null object\n",
      "brand listing        1980 non-null float64\n",
      "checkout             1980 non-null float64\n",
      "conversion           1980 non-null float64\n",
      "generic listing      1980 non-null float64\n",
      "searched products    1980 non-null float64\n",
      "staticpage           1980 non-null float64\n",
      "viewed product       1980 non-null float64\n",
      "visited site         1980 non-null float64\n",
      "label                1980 non-null float64\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 154.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-501e9d78f4e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_final' is not defined"
     ]
    }
   ],
   "source": [
    "test_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19414 entries, 0 to 19413\n",
      "Data columns (total 10 columns):\n",
      "person               19414 non-null object\n",
      "label                19414 non-null int64\n",
      "brand listing        19414 non-null float64\n",
      "checkout             19414 non-null float64\n",
      "conversion           19414 non-null float64\n",
      "generic listing      19414 non-null float64\n",
      "searched products    19414 non-null float64\n",
      "staticpage           19414 non-null float64\n",
      "viewed product       19414 non-null float64\n",
      "visited site         19414 non-null float64\n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos guardamos los features que utilizaremos para los algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'brand listing', 'checkout', 'conversion', 'generic listing',\n",
       "       'searched products', 'staticpage', 'viewed product', 'visited site',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "f1 = 'ad campaign hit'\n",
    "f2 = 'brand listing'\n",
    "f3 = 'checkout'\n",
    "f4 = 'conversion'\n",
    "f5 = 'generic listing'\n",
    "f6 = 'search engine hit'\n",
    "f7 = 'viewed product'\n",
    "f8 = 'visited site'\n",
    "f9 = 'searched products'\n",
    "f10= 'staticpage'\n",
    "\n",
    "features = [f2,f3,f4,f5,f9,f10,f7,f8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionamos el set de entrenamiento para realizar pruebas locales de hiper-parámetros antes de realizar cada submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = 0.25\n",
    "random_s = 0\n",
    "\n",
    "x = np.array(train[train.iloc[:,2:].columns])\n",
    "y = np.array(train['label'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_s, random_state=random_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el set de entrenamiento para el test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_final = np.array(test_final[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos probados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores iniciales para K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALORES INICIALES PARA K\n",
      "La precisión para k= 5 es: 0.5128716904276986\n",
      "La precisión para k= 10 es: 0.4969450101832994\n",
      "La precisión para k= 20 es: 0.5\n",
      "La precisión para k= 50 es: 0.5\n",
      "La precisión para k= 60 es: 0.5\n",
      "La precisión para k= 75 es: 0.5\n",
      "La precisión para k= 80 es: 0.5\n",
      "Con k= 5 se obtuvo la mayor precisión: 0.5128716904276986\n",
      "Tiempo de ejecución: 0.18856 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "print('VALORES INICIALES PARA K')\n",
    "\n",
    "k_valores = [5,10,20,50,60,75,80]\n",
    "mejor_k = 0\n",
    "mejor_precision = 0\n",
    "\n",
    "for k in k_valores:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred = knn.predict(x_test)\n",
    "    precision = roc_auc_score(y_test, pred)\n",
    "    print('La precisión para k=', k, 'es:',precision)\n",
    "    if precision > mejor_precision:\n",
    "        mejor_precision = precision\n",
    "        mejor_k = k\n",
    "        \n",
    "print('Con k=', mejor_k, 'se obtuvo la mayor precisión:', mejor_precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores grid search para K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALORES GRID SEARCH PARA K\n",
      "La precisión para k = 3 es: 0.524725050916497\n",
      "La precisión para k = 4 es: 0.5159266802443992\n",
      "La precisión para k = 5 es: 0.5128716904276986\n",
      "La precisión para k = 6 es: 0.49490835030549896\n",
      "La precisión para k = 7 es: 0.4938900203665988\n",
      "Con k= 3 se obtuvo la mayor precisión: 0.524725050916497\n",
      "Tiempo de ejecución: 0.07969 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "print('VALORES GRID SEARCH PARA K')\n",
    "\n",
    "k_valores = []\n",
    "\n",
    "for i in range(mejor_k-2, mejor_k+3):\n",
    "    k_valores.append(i)\n",
    "    \n",
    "for k in k_valores:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred = knn.predict(x_test)\n",
    "    precision = roc_auc_score(y_test, pred)\n",
    "    print('La precisión para k =', k, 'es:',precision)\n",
    "    if precision > mejor_precision:\n",
    "        mejor_precision = precision\n",
    "        mejor_k = k\n",
    "        \n",
    "print('Con k=', mejor_k, 'se obtuvo la mayor precisión:', mejor_precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecimos el test final con el mejor k obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8a1242e33cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Predecimos las postulaciones del set final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpred_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test_final' is not defined"
     ]
    }
   ],
   "source": [
    "# Creamos el KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=mejor_k)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "knn.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = knn.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "#submit.to_csv('submits/submit_knn.csv', index=False)\n",
    "\n",
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5\n",
      "Tiempo de ejecución: 0.09852 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_rf = {'n_estimators':50, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "# Creamos el Random Forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "random_forest.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = random_forest.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f0f0aaf860a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Predecimos las postulaciones del set final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpred_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test_final' is not defined"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el random forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "random_forest.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = random_forest.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el random forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "random_forest.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = random_forest.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_random_forest_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extra Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5\n",
      "Tiempo de ejecución: 0.14353 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_et = {'n_estimators':100, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "# Creamos el extra_trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "extra_trees.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = extra_trees.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-95395c92302a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Predecimos las postulaciones del set final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpred_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_trees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test_final' is not defined"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el extra trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "extra_trees.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = extra_trees.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el extra trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "extra_trees.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = extra_trees.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_extra_trees.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_extra_trees_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.6092668024439919\n",
      "Tiempo de ejecución: 0.15079 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "naive_bayes.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = naive_bayes.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "naive_bayes.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = naive_bayes.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "naive_bayes.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = naive_bayes.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_naive_bayes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_naive_bayes_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5067617107942973\n",
      "Tiempo de ejecución: 0.00409 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el perceptron\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "perceptron.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = perceptron.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el perceptron\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "perceptron.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = perceptron.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_perceptron.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Adaptive Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.564908350305499\n",
      "Tiempo de ejecución: 0.12199 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_ab = {'n_estimators':50}\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "ada_boost.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = ada_boost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "ada_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = ada_boost.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "ada_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = ada_boost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_ada_boost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_ada_boost_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5059266802443991\n",
      "Tiempo de ejecución: 0.19208 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_gb = {'learning_rate':0.1, 'n_estimators':150, 'max_depth':4, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'subsample':0.5, 'max_features':'sqrt', 'warm_start':True}\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "gra_boost.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = gra_boost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "gra_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = gra_boost.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "gra_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = gra_boost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_gra_boost.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_gra_boost_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5169450101832994\n",
      "Tiempo de ejecución: 0.06409 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "log_reg.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = log_reg.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "log_reg.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = log_reg.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "log_reg.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = log_reg.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_log_reg.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_log_reg_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5533401221995926\n",
      "Tiempo de ejecución: 0.00646 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_dt = {'criterion':'entropy', 'splitter':'best', 'max_depth':None, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'max_features':'sqrt', 'presort':True}\n",
    "\n",
    "# Creamos el logistic regression\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "decision_tree.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = decision_tree.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el decision tree\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "decision_tree.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = decision_tree.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el decision tree\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "decision_tree.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = decision_tree.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_decision_tree.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_decision_tree_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Con Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5079633401221997\n",
      "Tiempo de ejecución: 3.71498 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_bag_lr = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "bagging.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = bagging.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "params_optimos_bag_lr = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = bagging.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "params_optimos_bag_lr = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = bagging.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_bagging_log_reg.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_bagging_log_reg_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Con Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5379633401221997\n",
      "Tiempo de ejecución: 0.05016 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_bag_dt = {'base_estimator':DecisionTreeClassifier(**params_optimos_dt), 'n_estimators':10, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "bagging.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = bagging.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = bagging.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = bagging.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_bagging_decision_tree.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_bagging_decision_tree_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5269450101832994\n",
      "Tiempo de ejecución: 12.34042 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariano/ENTER/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Creamos los estimadores base que utilizaremos para el voting\n",
    "estimador_1 = DecisionTreeClassifier(**params_optimos_dt)\n",
    "estimador_2 = GradientBoostingClassifier(**params_optimos_gb)\n",
    "estimador_3 = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Los agregamos a la lista de estimadores\n",
    "estimadores = []\n",
    "estimadores.append(('Naive Bayes', estimador_1))\n",
    "estimadores.append(('Logistic Regression', estimador_2))\n",
    "estimadores.append(('Random Forest', estimador_3))\n",
    "\n",
    "# Creamos el voting\n",
    "voting = VotingClassifier(estimators=estimadores)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "voting.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = voting.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el voting\n",
    "voting = VotingClassifier(estimators=estimadores)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "voting.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = voting.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_voting.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5208350305498982\n",
      "Tiempo de ejecución: 2.54249 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariano/ENTER/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\\n",
    "                            subsample=0.7,\\\n",
    "                            #colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "xgboost.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred_final = xgboost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = roc_auc_score(y_test, pred_final)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "xgboost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = xgboost.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "xgboost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = xgboost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "#submit.to_csv('submits/submit_xgboost.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "#submit_proba.to_csv('submits/submit_xgboost_proba.csv', index=False)\n",
    "roc_auc_score(np.array(test_final['label']),pred_final_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no = submit_proba['sepostulo'] < 0.5\n",
    "#si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "#cant_no = submit_proba.loc[(no)].count()\n",
    "#cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "#print(\"0   \", cant_no[1])\n",
    "#print(\"1   \", cant_si[1])\n",
    "#print(\"Name: sepostulo, dtype: int64\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
